{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDBhSGuZnPZsJh5r1mNAcM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laryssafsp/DIO-Ciencia-de-Dados-Python/blob/main/Python-ML-Pr%C3%A1tica/Rede_neural_do_zero_DIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rede Neural\n",
        "Implementando uma Deep Learning do zero em Python"
      ],
      "metadata": {
        "id": "nWUBIojYhxfI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jdmusaSpg5AB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() #define conversão imagem para tensor\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # carrega a parte do treino no dataset\n",
        "trainload = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # cria buffer dos dados para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # carrega a parte do treino no dataset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)# cria buffer dos dados para pegar os dados por partes\n",
        "\n",
        "#diretor IA no facebook yann.lecun"
      ],
      "metadata": {
        "id": "EiBlmcRsh2yZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainload)\n",
        "imagens, etiquetas = next(dataiter)\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "I_hboQCyh88p",
        "outputId": "35e8eaa7-de29-49f4-fad5-6526dd3bbbc0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) #verificar dimensões do tensor\n",
        "print(etiquetas[0].shape)#verificar dimensões etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJTPyQuziEl6",
        "outputId": "fe227706-5501-4f80-f39e-07126bad92eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo, self).__init__()\n",
        "    self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
        "    self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurôios que se ligam a 64\n",
        "    self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurôios que se ligam a 10\n",
        "# para a camada de sáida não é necessário definir nada, pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.linear1(X)) # função de ativação da camada de entrar a para a camada interna 1\n",
        "    X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 apara a camada interna 2\n",
        "    X = self.linear3(X) # função de ativação da camada interna 2 para a camda de saída, nesse cado f(x) = x\n",
        "    return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "qwpXv1w4ifed"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a politica de atualização dos pesos e da bias\n",
        "  inicio = time() # timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "  criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
        "  EPOCHS = 10 # numero de epochs que o algotirmo rodará - no mínimo 100\n",
        "  modelo.train() # ativando o modo de treinamento do modelo\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0 # inicialização da perda acumulada de apoch em questão\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "\n",
        "      imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compatíveis com a bias\n",
        "      otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "      output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device)) #calculando a perda da epoch em questão\n",
        "\n",
        "      perda_instantanea.backward() # back propagation a partir da perda\n",
        "\n",
        "      otimizador.step() # atuaizando os pesos e a bias\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item()\n",
        "\n",
        "\n",
        "    else:\n",
        "      print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "  print(\"\\nTempo de treino (em minutos) = \",(time()-inicio)/60)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_5RbSfcbihss"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, 784)\n",
        "        # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo algo de processamento\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device)) # output do modelo em escala loogaritmica\n",
        "\n",
        "      ps = torch.exp(logps) # converter output para escala normal (lembrando que é um tensor)\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "      etiqueta_pred = probab.index(max(probab)) # conveerter o tensor em um número, no caso, o numero que o modelo previu como correto\n",
        "      etiqueta_certa = etiquetas.numpy()[i]\n",
        "      if(etiqueta_certa == etiqueta_pred): # comparar a previsão com o valor correto\n",
        "        conta_corretas += 1\n",
        "      conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100*conta_todas))"
      ],
      "metadata": {
        "id": "5n-pXGfuijgL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificação\n",
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyqbNXQyikyq",
        "outputId": "e0d12224-da24-4dd9-8aa1-229bb970408e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}